# ðŸ” Machine Learning Loss Functions

> ðŸ“˜ Educational Project: This repository is for educational purposes only.
> It demonstrates the theory, implementation, and visualization of common ML loss functions using Python and NumPy.

This project implements and visualizes essential loss functions used in Machine Learning, both for **regression** and **classification**. Each loss is covered with:

- ðŸ“Œ Mathematical formula & explanation
- ðŸ§  Gradient derivation
- ðŸ§ª Code implementation (from scratch using NumPy)
- ðŸ“Š Visualizations of the loss curve
- ðŸ§¾ Use-case and comparison documentation

---

## ðŸ“ Folder Structure
ml-loss-functions/

â”œâ”€â”€ regression/ # MSE, MAE, Huber

â”œâ”€â”€ classification/ # BCE, CCE, Hinge

â”œâ”€â”€ graphs/ # All generated visualizations

â”œâ”€â”€ utils/ # Unified test runner

â”œâ”€â”€ report.md # In-depth theoretical report

â”œâ”€â”€ README.md # Project overview

â””â”€â”€ requirements.txt # Dependencies


---

## ðŸ§ª ðŸ” Test Case Demonstration

This project includes a script (`Utils/test_cases.py`) that runs all implemented loss functions on various sample inputs to demonstrate correctness and usability.

### ðŸ“¥ Test Input
![Test Input](graphs/Input.png)

> âœ… This image shows sample test cases including different predictions and labels across both regression and classification loss functions.

### ðŸ“¤ Test Output
![Test Output](graphs/Output.png)

> ðŸŽ¯ The above output reflects the computed loss values and gradients printed for each function when the script is run. This helps validate the implementation with real data.

> ðŸ§ª Run the test script using:
```bash
python Utils/test_cases.py

```


---

## ðŸ“š Loss Functions Covered

| Category         | Loss Function            | File                              |
|------------------|--------------------------|-----------------------------------|
| Regression       | Mean Squared Error (MSE) | `regression/mse.py`               |
|                  | Mean Absolute Error (MAE)| `regression/mae.py`               |
|                  | Huber Loss               | `regression/huber.py`             |
| Classification   | Binary Cross-Entropy     | `classification/binary_crossentropy.py` |
|                  | Categorical Cross-Entropy| `classification/categorical_crossentropy.py` |
|                  | Hinge Loss               | `classification/hinge.py`         |


## ðŸ“Š Loss Function Visualizations

### ðŸ”¹ MSE
![MSE](graphs/mse_graph.png)

### ðŸ”¹ MAE
![MAE](graphs/mae_graph.png)

### ðŸ”¹ Huber Loss
![Huber](graphs/huber_graph.png)

### ðŸ”¹ Binary Cross-Entropy
![BCE](graphs/binary_crossentropy_graph.png)

### ðŸ”¹ Categorical Cross-Entropy
![CCE](graphs/categorical_crossentropy_graph.png)

### ðŸ”¹ Hinge Loss
![Hinge](graphs/hinge_loss_graph.png)

---

## ðŸš€ Running the Project

1.  Install dependencies:

```bash
pip install -r requirements.txt
```

2.  python utils/test_cases.py

3.  Check graphs/ folder for all visualizations

4. Check report.md for:

   Full math derivations

   Gradient explanations

   When to use which loss

   Visual graph insights

##  Author
Chakshu Sharma

ðŸŽ“ B.Tech CSE | AI-ML Enthusiast

ðŸ“… Project Timeline: Juneâ€“July 2025

ðŸ“Œ Focus: Concept clarity + code implementation
